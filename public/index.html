<!doctype html><html lang=en dir=auto data-theme=auto><head><meta name=generator content="Hugo 0.152.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Francesco Argenziano</title><meta name=description content><meta name=author content><link rel=canonical href=https://fra-tsuna.github.io/website/><link crossorigin=anonymous href=/website/assets/css/stylesheet.72758e13ea3b92f05df82259bac79fda9645a40c6b4670a6f07c48a28d2b45ad.css integrity="sha256-cnWOE+o7kvBd+CJZusef2pZFpAxrRnCm8HxIoo0rRa0=" rel="preload stylesheet" as=style><link rel=icon href=https://fra-tsuna.github.io/website/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://fra-tsuna.github.io/website/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://fra-tsuna.github.io/website/favicon-32x32.png><link rel=apple-touch-icon href=https://fra-tsuna.github.io/website/apple-touch-icon.png><link rel=mask-icon href=https://fra-tsuna.github.io/website/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://fra-tsuna.github.io/website/index.xml title=rss><link rel=alternate hreflang=en href=https://fra-tsuna.github.io/website/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://fra-tsuna.github.io/website/"><meta property="og:site_name" content="Francesco Argenziano"><meta property="og:title" content="Francesco Argenziano"><meta property="og:locale" content="en-us"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Francesco Argenziano"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Francesco Argenziano","url":"https://fra-tsuna.github.io/website/","description":"","logo":"https://fra-tsuna.github.io/website/favicon.ico","sameAs":[]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://fra-tsuna.github.io/website/ accesskey=h title="Francesco Argenziano (Alt + H)">Francesco Argenziano</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://fra-tsuna.github.io/website/ title=Home><span class=active>Home</span></a></li><li><a href=https://fra-tsuna.github.io/website/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><div class=home-vertical><section class=home-hero><div class=hero-card><div class=hero-portrait><img src=/website/imgs/portrait.png alt="Portrait of Francesco Argenziano" loading=lazy></div><div class=hero-copy><p class=eyebrow>Research Profile</p><h1>Francesco Argenziano</h1><p class=lede>PhD student in Artificial Intelligence and Robotics at Sapienza University of Rome, focused on scene understanding, 3D scene graphs, and task planning.</p><a class=text-link href=/website/about/>Read the full bio</a><div class=hero-badges><a class=badge-link href="https://scholar.google.com/citations?user=TCqScyQAAAAJ&amp;hl=it" aria-label="Google Scholar"><img src=/website/svg/googles-cholar-svgrepo-com.svg alt aria-hidden=true loading=lazy>
</a><a class=badge-link href=https://www.linkedin.com/in/fra-arg/ aria-label=LinkedIn><img src=/website/svg/linkedin-161-svgrepo-com.svg alt aria-hidden=true loading=lazy>
</a><a class=badge-link href=https://github.com/Fra-Tsuna aria-label=GitHub><img src=/website/svg/github-142-svgrepo-com.svg alt aria-hidden=true loading=lazy></a></div></div></div></section><section class=home-news id=news><div class=section-header><h2>News</h2></div><ul class=news-list><li><div class=news-row><time datetime=2026-02-04>Feb 2026</time><span>Our paper "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning" has been accepted to ICRA 2026 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2026-01-01>Jan 2026</time><span>Our paper "LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments" has been accepted to the WACV 2026 SG4SI workshop ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2025-10-01>Oct 2025</time><span>Our paper "Dynamic Objects Relocalization in Changing Environments with Flow Matching" got nominated as Best Paper Finalist at the Perception and Planning for Mobile Manipulation in Changing Environments Workshop ğŸ†!</span></div></li><li><div class=news-row><time datetime=2025-10-01>Oct 2025</time><span>In Hangzhou ğŸ‡¨ğŸ‡³ for IROS 2025 ğŸ§³!</span></div></li><li><div class=news-row><time datetime=2025-09-15>Sep 2025</time><span>Our paper "Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning" to ICTAI 2025 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2025-09-01>Sep 2025</time><span>Our paper "Object-Centric Agentic Robot Policies" has been accepted to the SPACE in Vision, Language, and Embodied AI Workshop at NeurIPS 2025 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2025-09-01>Sep 2025</time><span>Our paper "Dynamic Objects Relocalization in Changing Environments with Flow Matching" has been accepted to the Perception and Planning for Mobile Manipulation in Changing Environments Workshop at IROS 2025 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2025-06-01>Jun 2025</time><span>Ended my Visiting PhD period âœ…!</span></div></li><li><div class=news-row><time datetime=2025-02-01>Feb 2025</time><span>Started my Visiting PhD period at Mila - Quebec AI Institute in Montreal to work with Prof. Liam Paull ğŸ“!</span></div></li><li><div class=news-row><time datetime=2024-10-19>Oct 2024</time><span>In Santiago de Compostela ğŸ‡ªğŸ‡¸ for ECAI 2024 ğŸ§³!</span></div></li><li><div class=news-row><time datetime=2024-10-14>Oct 2024</time><span>In Abu Dhabi ğŸ‡¦ğŸ‡ª for IROS 2024 ğŸ§³!</span></div></li><li><div class=news-row><time datetime=2024-07-29>Jul 2024</time><span>Attending the MRS 2024 Summer School ğŸ“š in Prague ğŸ‡¨ğŸ‡¿!</span></div></li><li><div class=news-row><time datetime=2024-07-14>Jul 2024</time><span>In Eindhoven ğŸ‡³ğŸ‡± for RoboCup 2024 âš½!</span></div></li><li><div class=news-row><time datetime=2024-07-01>Jul 2024</time><span>Our papers "Neural reward machines" and "Multi-Agent Planning Using Visual Language Models" have been accepted to ECAI 2024 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2024-06-30>Jun 2024</time><span>Our paper "EMPOWER: embodied multi-role open-vocabulary planning with online grounding and execution" has been accepted to IROS 2024 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2024-05-01>May 2024</time><span>Honored to have received the award of top 2% of Graduate Students in Sapienza for the year 2021/2022 ğŸ†!</span></div></li><li><div class=news-row><time datetime=2023-07-14>Jul 2023</time><span>In Daegu ğŸ‡°ğŸ‡· for RSS 2023!</span></div></li><li><div class=news-row><time datetime=2023-06-10>Jun 2023</time><span>Attending the ACDL 2023 Summer School ğŸ“š in Grosseto ğŸ‡®ğŸ‡¹!</span></div></li><li><div class=news-row><time datetime=2023-05-29>May 2023</time><span>Our paper "Enhancing Graph Representation of the Environment through Local and Cloud Computation" has been accepted to the Robot Representations for Scene Understanding, Reasoning and Planning Workshop at RSS 2023 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2023-05-03>May 2023</time><span>Our paper "Visual reward machines" has been accepted to NeSy 2023 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2022-11-28>Nov 2022</time><span>In Udine ğŸ‡®ğŸ‡¹ for AIxIA 2022 ğŸ§³!</span></div></li><li><div class=news-row><time datetime=2022-11-02>Nov 2022</time><span>Our paper "Knowledge acquisition and completion for long-term human-robot interactions using knowledge graph embedding" has been accepted to AIxIA 2022 ğŸ‰!</span></div></li><li><div class=news-row><time datetime=2022-11-01>Nov 2022</time><span>Start of my PhD journey ğŸ“!</span></div></li></ul></section><section class=home-publications id=publications><div class=section-header><h2>Publications</h2></div><div class=pub-list><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/wacv.png alt="LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments</h3></div><p class=pub-venue>Workshop on Scene Graph for Structured Intelligence @ IEEE/CVF Winter Conference on Applications of Computer Vision (<strong>WACV</strong>), 2026</p><p class=pub-authors><a href="https://www.linkedin.com/in/sara-micol-ferraina-85313a1a9/?originalSubdomain=it">Sara Micol Ferraina</a>; <a href=https://michelebri.github.io/>Michele Brienza</a>; <strong>Francesco Argenziano</strong>; <a href=https://sites.google.com/view/emanuelemusumeci/home>Emanuele Musumeci</a>; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://dbloisi.github.io/>Domenico D Bloisi</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a></p><div class=pub-links><a class=pub-link-pill href=https://lab-rococo-sapienza.github.io/lost-3dsg/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href=https://arxiv.org/pdf/2601.02905v1><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Lab-RoCoCo-Sapienza/lost-3dsg><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/icra_asp.png alt="Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action</h3></div><p class=pub-venue>arXiv preprint arXiv:2509.19571</p><p class=pub-authors><a href=https://sachamorin.github.io/>Sacha Morin</a>; <a href=https://www.kumaradityag.com/>Kumaraditya Gupta</a>; <a href="https://scholar.google.com/citations?hl=en&user=Gdv8B50AAAAJ&view_op=list_works&sortby=pubdate">Mahtab Sandhu</a>; <a href=https://velythyl.github.io/>Charlie Gauthier</a>; <strong>Francesco Argenziano</strong>; <a href=https://www.linkedin.com/in/kirsty-ellis-943b8245/>Kirsty Ellis</a>; <a href=https://liampaull.ca/>Liam Paull</a></p><div class=pub-links><a class=pub-link-pill href=https://montrealrobotics.ca/agentic-scene-policies.github.io/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href=https://arxiv.org/pdf/2509.19571><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><span class="pub-link-pill is-muted"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></span></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/icra.png alt="Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning</h3></div><p class=pub-venue>IEEE International Conference on Robotics & Automation (<strong>ICRA</strong>), 2025</p><p class=pub-authors><strong>Francesco Argenziano</strong>*; <a href=https://sites.google.com/view/emanuelemusumeci/home>Emanuele Musumeci*</a>; <a href=https://michelebri.github.io/>Michele Brienza*</a>; <a href=https://www.linkedin.com/in/hakim-drid/>Abdel Hakim Drid</a>; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a>; <a href=https://dbloisi.github.io/>Domenico D Bloisi</a></p><div class=pub-links><a class=pub-link-pill href=https://lab-rococo-sapienza.github.io/context-matters/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href=https://arxiv.org/pdf/2506.15828><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Lab-RoCoCo-Sapienza/context-matters><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/ictai.png alt="Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning</h3><span class=pub-award>Oral Presentation</span></div><p class=pub-venue>IEEE International Conference on Tools with Artificial Intelligence (<strong>ICTAI</strong>), 2025</p><p class=pub-authors><strong>Francesco Argenziano</strong>; <a href="https://www.linkedin.com/in/elena-umili-b65a89183/?originalSubdomain=it">Elena Umili</a>; <a href=https://www.diag.uniroma1.it/leotta/>Francesco Leotta</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a></p><div class=pub-links><a class=pub-link-pill href=https://fra-tsuna.github.io/llm-to-symbolic-planner/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href=https://arxiv.org/pdf/2509.16006><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Fra-Tsuna/llm-to-symbolic-planner><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/iros25.png alt="Dynamic Objects Relocalization in Changing Environments with Flow Matching cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Dynamic Objects Relocalization in Changing Environments with Flow Matching</h3><span class=pub-award>Best Paper Finalist</span></div><p class=pub-venue>Workshop on Perception and Planning for Mobile Manipulation in Changing Environments @ IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>), 2025</p><p class=pub-authors><strong>Francesco Argenziano</strong>*; <a href=https://mikes96.github.io/>Miguel Saavedra-Ruiz*</a>; <a href=https://sachamorin.github.io/>Sacha Morin</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a>; <a href=https://liampaull.ca/>Liam Paull</a></p><div class=pub-links><a class=pub-link-pill href=https://arxiv.org/pdf/2509.16398><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Fra-Tsuna/flowmaps><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/neurips.png alt="Object-Centric Agentic Robot Policies cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Object-Centric Agentic Robot Policies</h3><span class=pub-award>Poster Presentation</span></div><p class=pub-venue>Workshop on Space in Vision, Language, and Embodied AI @ Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2025</p><p class=pub-authors><a href=https://sachamorin.github.io/>Sacha Morin</a>; <a href=https://www.kumaradityag.com/>Kumaraditya Gupta</a>; <a href="https://scholar.google.com/citations?hl=en&user=Gdv8B50AAAAJ&view_op=list_works&sortby=pubdate">Mahtab Sandhu</a>; <a href=https://velythyl.github.io/>Charlie Gauthier</a>; <strong>Francesco Argenziano</strong>; <a href=https://www.linkedin.com/in/kirsty-ellis-943b8245/>Kirsty Ellis</a>; <a href=https://liampaull.ca/>Liam Paull</a></p><div class=pub-links><a class=pub-link-pill href="https://openreview.net/attachment?id=ze5SVsXsmq&amp;name=pdf"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/iros_emp.png alt="EMPOWER: embodied multi-role open-vocabulary planning with online grounding and execution cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>EMPOWER: embodied multi-role open-vocabulary planning with online grounding and execution</h3><span class=pub-award>Oral Pitch Presentation</span></div><p class=pub-venue>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>), 2024</p><p class=pub-authors><strong>Francesco Argenziano</strong>; <a href=https://michelebri.github.io/>Michele Brienza</a>; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a>; <a href=https://dbloisi.github.io/>Domenico D Bloisi</a></p><div class=pub-links><a class=pub-link-pill href=https://lab-rococo-sapienza.github.io/empower/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10802251"><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Lab-RoCoCo-Sapienza/empower/><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/ecai_map.png alt="Multi-Agent Planning Using Visual Language Models cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Multi-Agent Planning Using Visual Language Models</h3><span class=pub-award>Oral Presentation</span></div><p class=pub-venue>European Conference on Artificial Intelligence (<strong>ECAI</strong>), 2024</p><p class=pub-authors><a href=https://michelebri.github.io/>Michele Brienza</a>; <strong>Francesco Argenziano</strong>; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://dbloisi.github.io/>Domenico D Bloisi</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a></p><div class=pub-links><a class=pub-link-pill href=https://lab-rococo-sapienza.github.io/map-vlm/><svg viewBox="0 0 24 24" aria-hidden="true"><circle cx="12" cy="12" r="9"/><path d="M3 12h18"/><path d="M12 3a14 14 0 010 18"/><path d="M12 3a14 14 0 000 18"/></svg>
<span>Project</span>
</a><a class=pub-link-pill href=https://ebooks.iospress.nl/volumearticle/70011><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/Lab-RoCoCo-Sapienza/map-vlm><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/ecai_nrm.png alt="Neural reward machines cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Neural reward machines</h3><span class=pub-award>Oral Presentation</span></div><p class=pub-venue>European Conference on Artificial Intelligence (<strong>ECAI</strong>), 2024</p><p class=pub-authors><a href="https://www.linkedin.com/in/elena-umili-b65a89183/?originalSubdomain=it">Elena Umili</a>; <strong>Francesco Argenziano</strong>; <a href=https://robertocapobianco.com/>Roberto Capobianco</a></p><div class=pub-links><a class=pub-link-pill href=https://ebooks.iospress.nl/volumearticle/69942><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/KRLGroup/NeuralRewardMachines><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/rss.png alt="Enhancing Graph Representation of the Environment through Local and Cloud Computation cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Enhancing Graph Representation of the Environment through Local and Cloud Computation</h3></div><p class=pub-venue>Workshop on Robot Representations for Scene Understanding, Reasoning and Planning @ Robotics: Science and Systems (<strong>RSS</strong>), 2023</p><p class=pub-authors><strong>Francesco Argenziano</strong>; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a></p><div class=pub-links><a class=pub-link-pill href=https://arxiv.org/pdf/2309.12692><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src="/website/imgs/nesy.png?v=20260116" alt="Visual reward machines cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Visual reward machines</h3></div><p class=pub-venue>International Workshop on Neural-Symbolic Learning and Reasoning (<strong>NeSy</strong>), 2023</p><p class=pub-authors><a href="https://www.linkedin.com/in/elena-umili-b65a89183/?originalSubdomain=it">Elena Umili</a>; <strong>Francesco Argenziano</strong>; <a href="https://scholar.google.com/citations?user=oB7yWcIAAAAJ&hl=en">Aymeric Barbin</a>; <a href=https://robertocapobianco.com/>Roberto Capobianco</a></p><div class=pub-links><a class=pub-link-pill href=https://ceur-ws.org/Vol-3432/paper23.pdf><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span>
</a><a class=pub-link-pill href=https://github.com/whitemech/VisualRewardMachine><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M8 9l-3 3 3 3"/><path d="M16 9l3 3-3 3"/><path d="M10 19l4-14"/></svg>
<span>Code</span></a></div></div></div></article><article class=pub-card><div class=pub-link><div class=pub-thumb><img src=/website/imgs/aixia.png alt="Knowledge acquisition and completion for long-term human-robot interactions using knowledge graph embedding cover" loading=lazy></div><div class=pub-body><div class=pub-title-row><h3 class=pub-title-link>Knowledge acquisition and completion for long-term human-robot interactions using knowledge graph embedding</h3><span class=pub-award>Oral Presentation</span></div><p class=pub-venue>International Conference of the Italian Association for Artificial Intelligence (<strong>AIxIA</strong>), 2022</p><p class=pub-authors><strong>Francesco Argenziano</strong>*; <a href="https://www.linkedin.com/in/ermanno-bartoli-9b2468180/?originalSubdomain=it">Ermanno Bartoli</a>*; <a href="https://www.linkedin.com/in/vincenzo-suriani-549429127/?originalSubdomain=it">Vincenzo Suriani</a>; <a href=https://www.diag.uniroma1.it/~nardi/>Daniele Nardi</a></p><div class=pub-links><a class=pub-link-pill href=https://arxiv.org/pdf/2301.06834><svg viewBox="0 0 24 24" aria-hidden="true"><path d="M14 2H6A2 2 0 004 4v16a2 2 0 002 2h12a2 2 0 002-2V8z"/><path d="M14 2v6h6"/></svg>
<span>Paper</span></a></div></div></div></article></div></section></div></main><footer class=footer><span>&copy; 2026 <a href=https://fra-tsuna.github.io/website/>Francesco Argenziano</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>